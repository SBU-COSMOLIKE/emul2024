{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e07cbf1d-272d-481d-bf54-ad97e280d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "#from scipy.interpolate import Akima1DInterpolator\n",
    "#from scipy.stats import multivariate_normal\n",
    "import time \n",
    "#import corner\n",
    "import h5py\n",
    "#import ipdb\n",
    "from scipy import integrate \n",
    "from tqdm import tqdm\n",
    "#import os\n",
    "import pandas as pd\n",
    "import camb \n",
    "from camb import model, initialpower\n",
    "from CosmologyCalculatorPC import CosmologyCalculatorPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d3eff3-1ff2-4295-98a9-e9164adc03fd",
   "metadata": {},
   "source": [
    "# Import - define all necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3deb57ff-0daf-4254-92a6-52fe6f72fde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redshifts for the bins that we chose when we did the eigevector analysis with Fisher.\n",
    "\n",
    "Nx = 1000\n",
    "zzmin = 0.03\n",
    "zzmax = 1.7\n",
    "zBinsFisher = np.array([zzmin + i * (zzmax - zzmin) / Nx for i in range(1, Nx + 1)])\n",
    "zbins = np.insert(zBinsFisher, 0, 0.03)\n",
    "\n",
    "alphasfid = np.array([0] * 1000) # When all amplitudes are zero, I get back ΛCDM\n",
    "\n",
    "eigenvectors = np.loadtxt(\"/mnt/c/Users/asgia/Desktop/cosmo_stuff/eigenvectorsFisherTot_ver2_1000PCs_0p03_to_1p7.dat\")\n",
    "#eigenvectors = np.loadtxt(\"/mnt/c/Users/asgia/Desktop/cosmo_stuff/eigenvectorsFisherTot_ver2.dat\")\n",
    "\n",
    "eigenvectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f1984a-e175-4ce2-b196-63cce7c6b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns fiducial ΛCDM distances\n",
    "calculator = CosmologyCalculatorPC(73,0.24, 0, alphasfid, eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de8f9b-6e67-4057-a370-ff9c7bb2c4b9",
   "metadata": {},
   "source": [
    "# Define the priors on the amplitudes $\\alpha_i$ following Mortonson et al (0810.1744)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb9a805-6397-4bc5-8fb7-c99baf60d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In order to define the correct prior for the PC amplitudes, I need to define the allowed min and max values for each alpha_i.\n",
    "## I can do that outside of the function that I will write below since these things do not change with each random step that the MCMC makes\n",
    "\n",
    "# Theoretical limits on DE\n",
    "wfid = -1\n",
    "# Quintessence\n",
    "wmin, wmax = -1, 1\n",
    "# Smooth DE\n",
    "# wmin, wmax = -5, 3\n",
    "weight1 = wmin + wmax - 2 * wfid\n",
    "weight2 = wmax - wmin \n",
    "\n",
    "# First I need to calculate each of the two relevant sums in the eq (A10)\n",
    "first_sum = np.sum(eigenvectors, axis=1)\n",
    "second_sum = np.sum(np.abs(eigenvectors), axis=1)\n",
    "\n",
    "## Nz is the number of z bins I used \n",
    "Nz = 1000\n",
    "\n",
    "# alpha_max and alpha_min are two arrays that are storing the max and min value of the amplitudes alpha_i \n",
    "alpha_max = ( 1 / (2*Nz)) * ( weight1 * first_sum + weight2 * second_sum)\n",
    "alpha_min = ( 1 / (2*Nz)) * ( weight1 * first_sum - weight2 * second_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b312912c-209e-4e6a-9cec-be7b6419b124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -0.03517969871824671)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_max[0], alpha_min[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176384d4-d4c7-477e-ab29-8a9ddd702a7c",
   "metadata": {},
   "source": [
    "- Define the limits of the sampling region for the amplitudes $\\alpha_i$. At this point I also need to decide how many $\\alpha_i$ I will keep.\n",
    "- I will sample only for $\\alpha_1$, $\\Omega_m$ and $H_0$. I will set to zero the rest of the PCs. Also, note that based on the calculation in the previous cell, I know the min and max values that are allowed for $\\alpha_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e546693a-c57f-4788-a2e1-b5f33bde98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##The fiducial model that I am using has Omega_m = 0.24 and h = 0.73 -- Omega_m h^2 = 0.127896 \n",
    "\n",
    "### Example case for 50 PCs\n",
    "low_lim = alpha_min[:50]\n",
    "high_lim = alpha_max[:50]\n",
    "\n",
    "low_lim = np.concatenate([alpha_min[:50],[65, 0.28 ]])\n",
    "high_lim = np.concatenate([alpha_max[:50],[75, 0.33]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8bd1802-e75b-4997-8bbd-75df5a4ea6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.89335473e-02, -2.12791266e-02,  1.14520050e-02, -1.22336940e-02,\n",
       "        1.46157822e-02,  2.12916358e-03, -9.76074152e-03, -1.11923960e-02,\n",
       "        1.14170467e-02,  1.87889170e-02,  3.75108480e-03,  1.63599726e-02,\n",
       "        2.27583451e-02,  1.89289160e-04,  9.83261690e-04,  2.23368667e-03,\n",
       "        1.42474440e-02,  1.06138816e-02,  3.46153502e-03, -1.25596716e-02,\n",
       "        6.64991583e-03, -2.09712066e-02,  1.17649604e-02, -9.27554232e-03,\n",
       "       -5.34356430e-03, -1.20301993e-02, -2.05470756e-02, -1.54714463e-02,\n",
       "        2.06874615e-02,  2.51147424e-03,  1.23021216e-02,  4.86583584e-03,\n",
       "       -1.63357787e-03, -1.14282434e-02,  8.86519491e-03,  6.78668148e-03,\n",
       "       -2.03610485e-02,  1.45160323e-02, -1.25352436e-02,  5.00287920e-03,\n",
       "       -1.33549975e-02,  2.19414371e-02, -1.59615086e-02, -8.56374935e-05,\n",
       "       -1.10445797e-02,  2.48762001e-02, -2.35277411e-02,  1.61516352e-02,\n",
       "        1.95180813e-02, -1.62506425e-02,  7.06501159e+01,  2.95513813e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(low=low_lim, high=high_lim, size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e9729-a1f3-42ae-9a9e-2ff27bec206e",
   "metadata": {},
   "source": [
    "### Generate the cosmological parameters vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e223378e-3bce-4f9d-a870-cdadefa1ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will save the uniform sampled cosmological parameters in an hdf5 file\n",
    "\n",
    "# with h5py.File('/gpfs/scratch/argiannakopo/uniform_cosmo_data_15PC.h5', 'w') as f:\n",
    "\n",
    "with h5py.File('/home/venus/cosmo_temp/uniform_sampling_res/uniform_cosmo_params_50PC.h5', 'w') as f:\n",
    "    # Will save things in chunks so that it is easier to load and read later\n",
    "    dataset = f.create_dataset('data', shape=(0, 52), maxshape=(None, 52), dtype=np.float64, chunks=True)\n",
    "\n",
    "    chunk_size = 10000  # Number of rows per chunk\n",
    "    for start in range(0, 100000, chunk_size):\n",
    "        end = min(start + chunk_size, 100000)\n",
    "        # Uniformly distributed values for the amplitudes α_i\n",
    "        chunk = np.random.uniform(low=low_lim, high=high_lim, size=(end - start, 52))\n",
    "        \n",
    "        dataset.resize((dataset.shape[0] + chunk.shape[0]), axis=0)\n",
    "        dataset[-chunk.shape[0]:] = chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0741a5f6-54fd-400a-8b56-b14c7d501a9a",
   "metadata": {},
   "source": [
    "### Import the cosmological parameter vectors from file and calculate the equivalent luminosity distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95c5bfd4-ae62-40da-95a9-65cc018a6f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 100000/100000 [09:05<00:00, 183.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Data saved to: /home/venus/cosmo_temp/uniform_sampling_res/uniform_logdl_vals_50PC.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Input and output file names\n",
    "# input_filename = '/gpfs/scratch/argiannakopo/uniform_cosmo_data_15PC.h5'\n",
    "# output_filename = '/gpfs/scratch/argiannakopo/uniform_lodL_data_15PC.h5'\n",
    "\n",
    "input_filename = '/home/venus/cosmo_temp/uniform_sampling_res/uniform_cosmo_params_50PC.h5'\n",
    "output_filename = '/home/venus/cosmo_temp/uniform_sampling_res/uniform_logdl_vals_50PC.h5'\n",
    "\n",
    "zeros = [0] * (1000 - 50)\n",
    "\n",
    "# Read the input file and process each row\n",
    "with h5py.File(input_filename, 'r') as f_in, h5py.File(output_filename, 'w') as f_out:\n",
    "    dataset_in = f_in['data']\n",
    "    num_rows, num_cols = dataset_in.shape\n",
    "    \n",
    "    \n",
    "    dataset_out = f_out.create_dataset('processed_data', shape=(num_rows, 1000), dtype=np.float64, chunks=True)\n",
    "    \n",
    "    # Process each row and save the result\n",
    "    for i in tqdm(range(num_rows)):\n",
    "        row = dataset_in[i]\n",
    "        alps = np.concatenate([row[:50],zeros])  \n",
    "        calculator50 = CosmologyCalculatorPC(row[-2], row[-1], 0, alps, eigenvectors)\n",
    "        processed_row = calculator50.lum_distance(zbins, zBinsFisher)\n",
    "        dataset_out[i] = np.log((row[-2] / 100) * processed_row)\n",
    "\n",
    "print(\"Processing complete. Data saved to:\", output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ec507-1d84-48e9-9c35-efb61624811a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ssi2023)",
   "language": "python",
   "name": "ssi_torchvision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
